---
id : A3.进程与线程
title : A3.进程与线程
typora-root-url : ../
---

# 进程管理

## 进程与线程

### 1. 进程

- **进程是资源分配的基本单位**，实现操作系统的并发，对于一个进程，它在被执行前其实是一个可执行程序。这个程序是被放在磁盘上的，当它要被执行的时候，它先被加载到内存当中，然后再放入到寄存器中，最后再让cpu执行该程序，这个时候一个静态的程序就变成了进程
- 进程创建时会分配4G的内存，其中0-3G是用户空间，3-4G是内核空间，PCB存在于内核空间
- 进程的用户空间是不同的，内核空间也是不同的。比如每个进程的不同系统调用，是陷入自己独立的内核空间里面，所以每个进程内核的堆栈肯定是不一样的

#### 进程的组成

- PCB
- 程序段：存放要执行的代码
- 数据段：存放程序运行过程中处理的各种数据

#### 相比于程序，进程的特征

- 动态性：进程是程序的一次执行过程，是动态地产生、变化和消亡的

- 并发性：内存中有多个进程实体，各进程可并发执行

- 独立性：进程是能独立运行、独立获得资源、独立接受调度的基本单位

- 异步性：各进程按各自独立的、不可预知的速度向前推进，操作系统要提供“进程同步机制"来解决异步问题

- 结构性：每个进程都会配置一个PCB。结构上看，进程由程序段、数据段、PCB组成

  



#### PCB

- 每个进程的PCB都是存在所有进程共享的内核空间中，操作系统管理进程，也就是在内核空间中管理的，在内核空间中通过链表管理所有进程的PCB，如果有一个进程要被创建，实际上多分配了这么一个4G的虚拟内存，并在共享的内核空间中的双向链表中加入了自己的PCB。
- 进程控制块 (Process Control Block, PCB) 描述进程的基本信息和运行状态，所谓的创建进程和撤销进程，都是指对 PCB 的操作。**创建进程，实际上是创建了进程实体中的PCB，而撤销进程就是撤销PCB，PCB是进程存在的唯一标志**。
- 内容
  - 标识相关：pid，ppid等等
  - 文件相关：进程需要记录打开的文件信息，于是需要文件描述符表
  - 内存相关：内存指针，指向进程的虚拟地址空间（用户空间）信息
  - 优先级相关：进程相对于其他进程的调度优先级
  - 上下文信息相关：CPU的所有寄存器中的值、进程的状态以及堆栈上的内容，当内核需要切换到另一个进程时，需要保存当前进程的所有状态，即保存当前进程的进程上下文，以便再次执行该进程时，能够恢复切换时的状态，继续执行。
  - 状态相关：进程当前的状态，说明该进程处于什么状态
  - 信号相关：进程的信号处理函数，以及记录当前进程是否还有待处理的信号
  - I/O相关：记录进程与各种I/O设备之间的交互
- 每个进程的内核空间中都有PCB，但真正的PCB是存储在物理内存上的，当进程创建和销毁时，会由操作系统操作PCB，每个进程只是虚拟地址空间，并不会存储实际数据，数据存储在物理内存中，只有一份。

下图显示了 4 个程序创建了 4 个进程，这 4 个进程可以并发地执行。

 [![img](/Image/A3.进程与线程-photo/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f61366163326230382d333836312d346538352d626161382d3338323238376266656539662e706e67)](https://camo.githubusercontent.com/eb5ec7711cffa59515302907e8a7ed8993f797d861a708eba3a07128908006e2/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f61366163326230382d333836312d346538352d626161382d3338323238376266656539662e706e67)



### 2. 线程

线程是资源调度的独立单位。

一个进程中可以有多个线程，它们共享进程资源。

QQ 和浏览器是两个进程，浏览器进程里面有很多线程，例如 HTTP 请求线程、事件响应线程、渲染线程等等，线程的并发执行使得在浏览器中点击一个新链接从而发起 HTTP 请求时，浏览器还可以响应用户的其它事件。

 [![img](/Image/A3.进程与线程-photo/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f33636436333065612d303137632d343838642d616431642d3733326234656665646466352e706e67)](https://camo.githubusercontent.com/403fa9a8094f89adcf827714e51e139f19d716c583792e1f33d81d9824899f5f/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f33636436333065612d303137632d343838642d616431642d3733326234656665646466352e706e67) 

### 3. 区别

1. 拥有资源

   - 进程是资源分配的基本单位，一个CPU同时刻只能执行一个进程

     - **单核CPU实现多进程，并发。** 通过操作系统的进程调度算法，单核CPU进行进程调度的时候，需要读取上下文+执行程序+保存上下文，即进程切换。
     - **多CPU实现多进程，并行。** 不同的进程运行在不同的CPU上。

   - 但是线程不拥有资源，线程可以访问隶属进程的资源。一个CPU核心同时刻只能执行一个线程

     - **单核CPU实现多线程，并发。** 不同线程为了使用CPU核心，则会进行线程切换，但是由于共享了程序执行环境，这个线程切换比进程切换开销少了很多。
     - **多核CPU实现多线程，并行。** CPU可以将不同线程分配到不同的CPU核心处理器中。

     

2. 调度 线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。

3. 进程的调度和资源分配是操作系统负责，线程的调度和资源分配是CPU负责

4. 进程在创建、销毁时开销比较大，而线程比较小。 由于创建或撤销进程时，系统都要为之分配或回收资源，进程创建的时候需要分配虚拟地址空间等系统资源，而销毁的的时候需要释放系统资源；线程只需要创建栈，栈指针，程序计数器，通用目的寄存器和条件码等，不需要创建独立的虚拟地址空间。

5. 进程切换开销比较打，线程比较小。进程切换需要分两步：切换页目录、刷新TLB以使用新的地址空间；切换内核栈和硬件上下文（寄存器）；而同一进程的线程间逻辑地址空间是一样的，不需要切换页目录、刷新TLB。 在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU  环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。

6. 通信方面 线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC。

7. 一个进程崩溃，不会对其他进程产生影响；而一个线程崩溃，会让同一进程内的其他线程也宕掉。



> - 单CPU中进程只能是并发，多CPU计算机中进程可以并行。
> - 单CPU单核中线程只能并发，单CPU多核中线程可以并行。
> - 并行有上限，进程与CPU个数，线程与CPU核心个数有关，并不是所有线程和所有进程都能同时运行

### [TLB](https://www.cnblogs.com/linhaostudy/p/7771437.html)

TLB( Translation Look- aside buffer)专门用于缓存内存中的页表项,一般在MMU单元内部，页表一般存储在屋里内存中。当处理器要访问一个虚拟地址时,首先会在TLB中查询。如果TLB表项中没有相应的表项,称为TLB Miss,那么就需要访问页表来计算出相应的物理地址。如果TLB表项中有相应的表项,那么直接从TLB表项中获取物理地址,称为TLB命中。 

### [程序计数器PC和指令指针寄存器IP](http://blog.sina.com.cn/s/blog_5ede281a0100sn4w.html)

- 程序计数器PC
  - 用指令事先编好的程序连续存放在内存程序区中，靠地址+1的方法连续取指执行”。在八位机8080CPU中是采用先取指后执行的串行操作的原理，而其中执行地址+1指令寻址的部件就是程序计数器PC。那么在程序的执行过程中，PC始终是指向下一条要执行的指令。
  - 结论：PC中的地址就是需要转移、循环、调用子程序和中断子程序等操作时的断点。
- 指令指针寄存器IP
  - 在向上兼容的十六位机8086CPU中首先分为两个功能部件，即总线接口部件BIU和执行部件EU，BIU负责取指令，EU负责译码执行。并且当BIU执行指令排队栈中的六个字节装满后，（8088CPU是4个字节），EU开始从指令排队栈的出栈口，取指令进行译码执行，同时BIU并行操作向入栈口补充一条取指令命令。
  - 指令指针IP则是指向下个条要取指的指令，而不是EU要执行的指令。而断点则应该是要执行的指令内存地址，而不是IP内的下一条要取指的指令地址。
- PC是模型机中的概念，IP是实际使用的，调试时我们发现，IP实现的就是PC的功能。

### 为什么有了进程还需要线程？

- 优点
  - 进程可以使多个程序能并发执行，以提高资源的利用率和系统的吞吐量.
- 缺点
  - 进程在同一时间只能干一件事
  - 进程在执行的过程中如果阻塞，整个进程就会挂起，即使进程中有些工作不依赖于等待的资源，仍然不会执行。

因此，操作系统引入了比进程粒度更小的线程，作为并发执行的基本单位，从而减少程序在并发执行时所付出的时空开销，提高并发性

### 什么时候使用多进程和多线程

- 多核CPU——计算密集型任务。此时要尽量使用多线程，可以提高任务执行效率，例如加密解密，数据压缩解压缩（视频、音频、普通数据），否则只能使一个核心满载，而其他核心闲置.
- 单核CPU——计算密集型任务。此时的任务已经把CPU资源100%消耗了，就没必要也不可能使用多线程来提高计算效率了；相反，如果要做人机交互，最好还是要用多线程，避免用户没法对计算机进行操作。
- 单核CPU——IO密集型任务，使用多线程还是为了人机交互方便.
- 多核CPU——IO密集型任务，这就更不用说了，跟单核时候原因一样。



## 进程状态的切换

 [![img](/Image/A3.进程与线程-photo/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f50726f6365737353746174652e706e67)](https://camo.githubusercontent.com/0398c2bace5b1b0695f5a34f6cfedf6e358db565408abc83dd161de71d3bfec8/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f50726f6365737353746174652e706e67) 

### 三种基本状态

- 就绪状态（ready）：等待被调度，已经具备运行条件，位于进程的就绪队列中，等待进程调度被分配CPU资源
- 运行状态（running）：当前占据CPU资源的进程的状态
- 阻塞状态（waiting）：等待资源，处于运行态的进程因发出某种资源请求，操作系统将其CPU资源剥夺，等待请求的事件满足，再变成就绪态，加入就绪队列。应该注意以下内容：
- 只有就绪态和运行态可以相互转换，其它的都是单向转换。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。
- 阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括 CPU 时间，缺少 CPU 时间会从运行态转换为就绪态。

### 进程的创建和撤销

- 创建态：进程正在被创建，操作系统需要为其分配资源、初始化PCB
- 终止态：进程正在从系统中撤销，操作系统会回收进程拥有的资源、撤销PCB。

这两个状态是瞬态，没有哪个进程会长时间停留在此。

![进程转换知识点总结](file:///home/worst/Nutstore%20Files/1.MyNote/5.Operating_system/4.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/img/%E8%BF%9B%E7%A8%8B%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.png?lastModify=1633522759?lastModify=1633575807)

## 进程调度时机

> - 进程状态转换的时刻：进程终止、进程睡眠；
> - 当前进程的时间片用完时（current->counter=0）；
> - 设备驱动程序
> - 进程从中断、异常及系统调用返回到用户态时；

- 需要进行调度时机
  - 当前处于运行态的进程**主动**放弃CPU
    - 进程正常终止
    - 异常终止
    - 进程主动请求资源而被堵塞（比如I/O响应）
  - 当前运行的进程**被动**放弃CPU
    - 分给进程的时间片用完
    - 有更紧急的事需要处理（比如中断）
    - 有更高优先级的进程进入就绪队列
- 不能进程调度的时机   下面三个状态下的进程，只能等进程运行结束，系统才可以进行调度。
  - 在处理中断的过程中
  - 进程处于操作系统内核临界区中
  - 在原子操作过程中





## 进程调度算法

不同环境的调度算法目标不同，因此需要针对不同环境来讨论调度算法。

### 周转时间

周转时间 = 作业完成时间 - 作业提交时间。 

平均周转时间 = 各个作业周转时间之和 / 作业数



### 1. 批处理系统

批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。

**1.1 先来先服务 first-come first-serverd（FCFS）**

> - 非抢占式的调度算法，按照请求的顺序进行调度。
> - 有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。

**1.2 短作业优先 shortest job first（SJF）**

> - 非抢占式的调度算法，按估计运行时间最短的顺序进行调度。
> - 长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。

**1.3 最短剩余时间优先 shortest remaining time next（SRTN）**

> - 最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 
> - 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。



### 2. 交互式系统

交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。

**2.1 时间片轮转**

> - 将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。
> - 当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。

时间片轮转算法的效率和时间片的大小有很大关系：

- 因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。
- 而如果时间片过长，那么实时性就不能得到保证。

 [![img](/Image/A3.进程与线程-photo/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f38633636323939392d633136632d343831632d396634302d3166646261356263393136372e706e67)](https://camo.githubusercontent.com/a87daa8201015ff54a213d9ea95c1e49e7eec447938c441dd0247e80b18eaa05/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f38633636323939392d633136632d343831632d396634302d3166646261356263393136372e706e67) 



**2.2 优先级调度**

> - 为每个进程分配一个优先级，按优先级进行调度。
> - 为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

**2.3 多级反馈队列**

> - 一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。
> - 多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。
> - 每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。

可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。

 [![img](https://camo.githubusercontent.com/c20fd7a3268ebc4ef0bce390344de2c5358392ecef2413d849c3095e21047980/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f30343263663932382d336338652d343831352d616539632d6632373830323032633638662e706e67)](https://camo.githubusercontent.com/c20fd7a3268ebc4ef0bce390344de2c5358392ecef2413d849c3095e21047980/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f30343263663932382d336338652d343831352d616539632d6632373830323032633638662e706e67) 

### 3. 实时系统

- 实时系统要求一个请求在一个确定时间内得到响应。
- 分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。



## 僵尸进程和孤儿进程

- 当父进程先结束，子进程此时就会变成孤儿进程，孤儿进程会自动向上被init进程收养，init进程完成对状态收集工作。而且这种过继的方式也是守护进程能够实现的因素。
- 如果子进程先结束，父进程并未调用wait或者waitpid获取进程状态信息，回收进程资源，那么子进程描述符就会一直保存在系统中，这种进程称为僵尸进程。
  - 僵尸进程是每个子进程退出时必然经历的过程
  - 僵尸进程的危害
    - 在每个进程退出的时候，内核释放该进程所有的资源，包括打开的文件，占用的内存等。但是仍然为其保留一定的信息（包括进程号the process ID，退出状态the termination status of the process，运行时间the amount of CPU time taken by the process等）。直到父进程通过wait / waitpid来取时才释放. 
    - 如果进程不调用wait / waitpid的话， 那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程。  
  - 如何消除僵尸进程
    - kill发送SIGTERM或者SIGKILL信号消灭产生僵尸进程的进程，它产生的僵死进程就变成了孤儿进程，这些孤儿进程会被init进程接管
    - 子进程退出时向父进程发送SIGCHILD信号，父进程处理SIGCHILD信号。在信号处理函数中调用wait进行处理僵尸进程。 



## 进程同步

### 1. 临界区

对临界资源进行访问的那段代码称为临界区。

为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。

```
// entry section
// critical section;
// exit section
```

### 2. 同步与互斥

- 同步：多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系。
- 互斥：多个进程在同一时刻只有一个进程能进入临界区。

### 3. 信号量

信号量（Semaphore）是一个整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。

- **down**   : 如果信号量大于 0 ，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0；
- **up**  ：对信号量执行 +1 操作，唤醒睡眠的进程让其完成 down 操作。

down 和 up 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。

如果信号量的取值只能为 0 或者 1，那么就成为了   **互斥量（Mutex）**  ，0 表示临界区已经加锁，1 表示临界区解锁。

```
typedef int semaphore;
semaphore mutex = 1;
void P1() {
    down(&mutex);
    // 临界区
    up(&mutex);
}

void P2() {
    down(&mutex);
    // 临界区
    up(&mutex);
}
```

**使用信号量实现生产者-消费者问题** 

问题描述：使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品。

因为缓冲区属于临界资源，因此需要使用一个互斥量 mutex 来控制对缓冲区的互斥访问。

为了同步生产者和消费者的行为，需要记录缓冲区中物品的数量。数量可以使用信号量来进行统计，这里需要使用两个信号量：empty  记录空缓冲区的数量，full 记录满缓冲区的数量。其中，empty 信号量是在生产者进程中使用，当 empty 不为 0  时，生产者才可以放入物品；full 信号量是在消费者进程中使用，当 full 信号量不为 0 时，消费者才可以取走物品。

注意，不能先对缓冲区进行加锁，再测试信号量。也就是说，不能先执行 down(mutex) 再执行  down(empty)。如果这么做了，那么可能会出现这种情况：生产者对缓冲区加锁后，执行 down(empty) 操作，发现 empty =  0，此时生产者睡眠。消费者不能进入临界区，因为生产者对缓冲区加锁了，消费者就无法执行 up(empty) 操作，empty 永远都为  0，导致生产者永远等待下，不会释放锁，消费者因此也会永远等待下去。

```
define N 100
typedef int semaphore;
semaphore mutex = 1;
semaphore empty = N;
semaphore full = 0;

void producer() {
    while(TRUE) {
        int item = produce_item();
        down(&empty);
        down(&mutex);
        insert_item(item);
        up(&mutex);
        up(&full);
    }
}

void consumer() {
    while(TRUE) {
        down(&full);
        down(&mutex);
        int item = remove_item();
        consume_item(item);
        up(&mutex);
        up(&empty);
    }
}
```

### 4. 管程

使用信号量机制实现的生产者消费者问题需要客户端代码做很多控制，而管程把控制的代码独立出来，不仅不容易出错，也使得客户端代码调用更容易。

c 语言不支持管程，下面的示例代码使用了类 Pascal 语言来描述管程。示例代码的管程提供了 insert() 和 remove() 方法，客户端代码通过调用这两个方法来解决生产者-消费者问题。

```
monitor ProducerConsumer
    integer i;
    condition c;

    procedure insert();
    begin
        // ...
    end;

    procedure remove();
    begin
        // ...
    end;
end monitor;
```

管程有一个重要特性：在一个时刻只能有一个进程使用管程。进程在无法继续执行的时候不能一直占用管程，否则其它进程永远不能使用管程。

管程引入了   **条件变量**   以及相关的操作：**wait()** 和 **signal()** 来实现同步操作。对条件变量执行 wait() 操作会导致调用进程阻塞，把管程让出来给另一个进程持有。signal() 操作用于唤醒被阻塞的进程。

  **使用管程实现生产者-消费者问题**  

```
// 管程
monitor ProducerConsumer
    condition full, empty;
    integer count := 0;
    condition c;

    procedure insert(item: integer);
    begin
        if count = N then wait(full);
        insert_item(item);
        count := count + 1;
        if count = 1 then signal(empty);
    end;

    function remove: integer;
    begin
        if count = 0 then wait(empty);
        remove = remove_item;
        count := count - 1;
        if count = N -1 then signal(full);
    end;
end monitor;

// 生产者客户端
procedure producer
begin
    while true do
    begin
        item = produce_item;
        ProducerConsumer.insert(item);
    end
end;

// 消费者客户端
procedure consumer
begin
    while true do
    begin
        item = ProducerConsumer.remove;
        consume_item(item);
    end
end;
```

## 经典同步问题

### 互斥同步问题分析

- 关系分析：找出问题中描述的各个进程，分析他们之间的同步、互斥关系
- 整理思路：根据各个进程的操作流程确定PV操作的顺序
- 设置信号量。设置需要的信号量，并且根据条件确定信号量初值。（一般互斥信号量初值为1，同步信号量要看对应的系统资源是多少）

### 1. 哲学家进餐问题

 [![img](/Image/A3.进程与线程-photo/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f61393037376630362d373538342d346632622d386332302d3361386534363932383832302e6a7067)](https://camo.githubusercontent.com/7f8eb6362323b56a5dd8ec061d7ea0c5b0d07a842132598bbed860a8bb941317/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f61393037376630362d373538342d346632622d386332302d3361386534363932383832302e6a7067) 



五个哲学家围着一张圆桌，每个哲学家面前放着食物。哲学家的生活有两种交替活动：吃饭以及思考。当一个哲学家吃饭时，需要先拿起自己左右两边的两根筷子，并且一次只能拿起一根筷子。

下面是一种错误的解法，如果所有哲学家同时拿起左手边的筷子，那么所有哲学家都在等待其它哲学家吃完并释放自己手中的筷子，导致死锁。

```
define N 5

void philosopher(int i) {
    while(TRUE) {
        think();
        take(i);       // 拿起左边的筷子
        take((i+1)%N); // 拿起右边的筷子
        eat();
        put(i);
        put((i+1)%N);
    }
}
```

为了防止死锁的发生，可以设置两个条件：

- 必须同时拿起左右两根筷子；
- 只有在两个邻居都没有进餐的情况下才允许进餐。

```
define N 5
define LEFT (i + N - 1) % N // 左邻居
define RIGHT (i + 1) % N    // 右邻居
define THINKING 0
define HUNGRY   1
define EATING   2
typedef int semaphore;
int state[N];                // 跟踪每个哲学家的状态
semaphore mutex = 1;         // 临界区的互斥，临界区是 state 数组，对其修改需要互斥
semaphore s[N];              // 每个哲学家一个信号量

void philosopher(int i) {
    while(TRUE) {
        think(i);
        take_two(i);
        eat(i);
        put_two(i);
    }
}

void take_two(int i) {
    down(&mutex);
    state[i] = HUNGRY;
    check(i);
    up(&mutex);
    down(&s[i]); // 只有收到通知之后才可以开始吃，否则会一直等下去
}

void put_two(i) {
    down(&mutex);
    state[i] = THINKING;
    check(LEFT); // 尝试通知左右邻居，自己吃完了，你们可以开始吃了
    check(RIGHT);
    up(&mutex);
}

void eat(int i) {
    down(&mutex);
    state[i] = EATING;
    up(&mutex);
}

// 检查两个邻居是否都没有用餐，如果是的话，就 up(&s[i])，使得 down(&s[i]) 能够得到通知并继续执行
void check(i) {         
    if(state[i] == HUNGRY && state[LEFT] != EATING && state[RIGHT] !=EATING) {
        state[i] = EATING;
        up(&s[i]);
    }
}
```



### 2. 读者-写者问题

允许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生。

一个整型变量 count 记录在对数据进行读操作的进程数量，一个互斥量 count_mutex 用于对 count 加锁，一个互斥量 data_mutex 用于对读写的数据加锁。

```
typedef int semaphore;
semaphore count_mutex = 1;
semaphore data_mutex = 1;
int count = 0;

void reader() {
    while(TRUE) {
        down(&count_mutex);
        count++;
        if(count == 1) down(&data_mutex); // 第一个读者需要对数据进行加锁，防止写进程访问
        up(&count_mutex);
        read();
        down(&count_mutex);
        count--;
        if(count == 0) up(&data_mutex);
        up(&count_mutex);
    }
}

void writer() {
    while(TRUE) {
        down(&data_mutex);
        write();
        up(&data_mutex);
    }
}
```

以下内容由 [@Bandi Yugandhar](https://github.com/yugandharbandi) 提供。

The first case may result Writer to starve. This case favous Writers  i.e no writer, once added to the queue, shall be kept waiting longer  than absolutely necessary(only when there are readers that entered the  queue before the writer).

```
int readcount, writecount;                   //(initial value = 0)
semaphore rmutex, wmutex, readLock, resource; //(initial value = 1)

//READER
void reader() {
<ENTRY Section>
 down(&readLock);                 //  reader is trying to enter
 down(&rmutex);                  //   lock to increase readcount
  readcount++;                 
  if (readcount == 1)          
   down(&resource);              //if you are the first reader then lock  the resource
 up(&rmutex);                  //release  for other readers
 up(&readLock);                 //Done with trying to access the resource

<CRITICAL Section>
//reading is performed

<EXIT Section>
 down(&rmutex);                  //reserve exit section - avoids race condition with readers
 readcount--;                       //indicate you're leaving
  if (readcount == 0)          //checks if you are last reader leaving
   up(&resource);              //if last, you must release the locked resource
 up(&rmutex);                  //release exit section for other readers
}

//WRITER
void writer() {
  <ENTRY Section>
  down(&wmutex);                  //reserve entry section for writers - avoids race conditions
  writecount++;                //report yourself as a writer entering
  if (writecount == 1)         //checks if you're first writer
   down(&readLock);               //if you're first, then you must lock the readers out. Prevent them from trying to enter CS
  up(&wmutex);                  //release entry section

<CRITICAL Section>
 down(&resource);                //reserve the resource for yourself - prevents other writers from simultaneously editing the shared resource
  //writing is performed
 up(&resource);                //release file

<EXIT Section>
  down(&wmutex);                  //reserve exit section
  writecount--;                //indicate you're leaving
  if (writecount == 0)         //checks if you're the last writer
   up(&readLock);               //if you're last writer, you must unlock the readers. Allows them to try enter CS for reading
  up(&wmutex);                  //release exit section
}
```

We can observe that every reader is forced to acquire ReadLock. On  the otherhand, writers doesn’t need to lock individually. Once the first writer locks the ReadLock, it will be released only when there is no  writer left in the queue.

From the both cases we observed that either reader or writer has to  starve. Below solutionadds the constraint that no thread shall be  allowed to starve; that is, the operation of obtaining a lock on the  shared data will always terminate in a bounded amount of time.

```
int readCount;                  // init to 0; number of readers currently accessing resource

// all semaphores initialised to 1
Semaphore resourceAccess;       // controls access (read/write) to the resource
Semaphore readCountAccess;      // for syncing changes to shared variable readCount
Semaphore serviceQueue;         // FAIRNESS: preserves ordering of requests (signaling must be FIFO)

void writer()
{ 
    down(&serviceQueue);           // wait in line to be servicexs
    // <ENTER>
    down(&resourceAccess);         // request exclusive access to resource
    // </ENTER>
    up(&serviceQueue);           // let next in line be serviced

    // <WRITE>
    writeResource();            // writing is performed
    // </WRITE>

    // <EXIT>
    up(&resourceAccess);         // release resource access for next reader/writer
    // </EXIT>
}

void reader()
{ 
    down(&serviceQueue);           // wait in line to be serviced
    down(&readCountAccess);        // request exclusive access to readCount
    // <ENTER>
    if (readCount == 0)         // if there are no readers already reading:
        down(&resourceAccess);     // request resource access for readers (writers blocked)
    readCount++;                // update count of active readers
    // </ENTER>
    up(&serviceQueue);           // let next in line be serviced
    up(&readCountAccess);        // release access to readCount

    // <READ>
    readResource();             // reading is performed
    // </READ>

    down(&readCountAccess);        // request exclusive access to readCount
    // <EXIT>
    readCount--;                // update count of active readers
    if (readCount == 0)         // if there are no readers left:
        up(&resourceAccess);     // release resource access for all
    // </EXIT>
    up(&readCountAccess);        // release access to readCount
}
```



## forkv fork clone

fork、v_fork、clone底层都是do_fork，追踪发现底层使用的是sys_clone

- fork
  - 父进程fork之后创建子进程，子进程复制父进程的所有资源，子进程的代码段、数据段、堆栈都是指向父进程的物理空间，但此时仅仅是子进程的虚拟地址空间和父进程指向的物理地址空间建立了映射关系，并没有真正复制
  - 由于fork()后会产生一个和父进程完全相同的子进程，但子进程在此后多会exec系统调用，处于效率考虑，linux中引入了“写时复制技术-Copy-On-Write”
  - 若两个进程一直只是读数据，则子进程一直不会复制，直到任一进程进行写操作
  - 父进程和子进程执行顺序没有规定，可以乱序执行
  - 读时共享，写时复制
- vfork
  - vfork也是创建一个子进程，但是子进程共享父进程的空间。在vfork创建子进程之后，父进程阻塞，直到子进程执行了exec()或者exit()。
  - 规定必须子进程先执行
  - 严格意义上讲，vfork产生的不叫进程，因为他没有独立的地址空间，和父进程共享同一个

## 进程通信

进程同步与进程通信很容易混淆，它们的区别在于：

- 进程同步：控制多个进程按一定顺序执行；
- 进程通信：进程间传输信息。

进程通信是一种手段，而进程同步是一种目的。也可以说，为了能够达到进程同步的目的，需要让进程进行通信，传输一些进程同步所需要的信息。

### 1. 管道

管道是通过调用 pipe 函数创建的，fd[0] 用于读，fd[1] 用于写。

```
include <unistd.h>
int pipe(int fd[2]);
```

它具有以下限制：

- 只支持半双工通信（单向交替传输）；
- 只能在父子进程或者兄弟进程中使用。

 [![img](/Image/A3.进程与线程-photo/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f35336364396164652d623061362d343339392d623464652d3766316662643036636466622e706e67)](https://camo.githubusercontent.com/af6ac5de61c835b0fe14c799c244632fa04239ef2ca9421eee543392353297c8/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f35336364396164652d623061362d343339392d623464652d3766316662643036636466622e706e67) 



### 2. FIFO

也称为命名管道，去除了管道只能在父子进程中使用的限制。

```
include <sys/stat.h>
int mkfifo(const char *path, mode_t mode);
int mkfifoat(int fd, const char *path, mode_t mode);
```

FIFO 常用于客户-服务器应用程序中，FIFO 用作汇聚点，在客户进程和服务器进程之间传递数据。

 [![img](/Image/A3.进程与线程-photo/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f32616335306238312d643932612d343430312d623965632d6632313133656363333037362e706e67)](https://camo.githubusercontent.com/8c4dd36cf4d1509b9c3ae0500085617fee811f7a83602a71e64769753b66b66b/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f32616335306238312d643932612d343430312d623965632d6632313133656363333037362e706e67) 



### 3. 消息队列

相比于 FIFO，消息队列具有以下优点：

- 消息队列可以独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难；
- 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法；
- 读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。

### 4. 信号量

它是一个计数器，用于为多个进程提供对共享数据对象的访问。

### 5. 共享存储

允许多个进程共享一个给定的存储区。因为数据不需要在进程之间复制，所以这是最快的一种 IPC。

需要使用信号量用来同步对共享存储的访问。

多个进程可以将同一个文件映射到它们的地址空间从而实现共享内存。另外 XSI 共享内存不是使用文件，而是使用内存的匿名段。

**要互斥的访问共享空间**

### 6. 套接字

与其它通信机制不同的是，它可用于不同机器间的进程通信。



### 进程之间的通信方式以及优缺点

进程间通信主要包括管道、系统IPC（包括消息队列、信号、共享内存等）、本地套接字socket。

- 管道（PIPE）
  - 有名管道：一种半双工的通信方式，它允许无亲缘关系进程间的通信
    - 优点：可以实现任意关系的进程间的通信
    - 缺点：
      1. 长期存于系统中，使用不当容易出错
      2. 缓冲区有限
  - 无名管道：一种半双工的通信方式，只能在具有亲缘关系的进程间使用（父子进程）
    - 优点：简单方便
    - 缺点：
      1. 局限于单向通信
      2. 只能创建在它的进程以及其有亲缘关系的进程之间
      3. 缓冲区有限
- 信号量（Semaphore）：一个计数器，可以用来控制多个线程对共享资源的访问
  - 优点：可以同步进程
  - 缺点：信号量有限
- 信号（Signal）：一种比较复杂的通信方式，用于通知接收进程某个事件已经发生
- 消息队列（Message Queue）：是消息的链表，存放在内核中并由消息队列标识符标识
  - 消息队列克服了信号传递信息少，管道缓冲区大小受限的缺点
  - 一个消息队列由一个标识符（即队列ID）来标记
  - 优点：可以实现任意进程间的通信，并通过系统调用函数来实现消息发送和接收之间的同步，无需考虑同步问题，方便
  - 缺点：信息的复制需要额外消耗 CPU 的时间，不适宜于信息量大或操作频繁的场合
- [共享内存](https://blog.csdn.net/hj605635529/article/details/73163513)（Shared Memory）：映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问，所以需要进行同步 ，一般与信号量配合使用。
  - shm
  - mmap 
  - 优点：无须复制，快捷，信息量大
  - 缺点：
    1. 通信是通过将共享空间缓冲区直接附加到进程的虚拟地址空间中来实现的，因此进程间的读写操作的同步问题
    2. 利用内存缓冲区直接交换信息，内存的实体存在于计算机中，只能同一个计算机系统中的诸多进程共享，不方便网络通信
- 套接字（Socket）：可用于不同计算机间的进程通信
  - 本地套接字用于本机不同进程间通信，另外普通套接字可以用于不同主机间的进程间通信。
  - 优点：
    1. 传输数据为字节级，传输数据可自定义，数据量小效率高
    2. 传输数据时间短，性能高
    3. 适合于客户端和服务器端之间信息实时交互
    4. 可以加密,数据安全性强
  - 缺点：需对传输的数据进行解析，转化成应用级的数据。



[共享内存底层原理](https://blog.csdn.net/joejames/article/details/37958017)

共享内存有两个，一个mmap，一个systemV的shmget

- 虚拟内存在硬盘上

### 不同进程如何访问共享内存？

### [进程异常退出共享内存会销毁吗](https://blog.csdn.net/brucexu1978/article/details/7728717)

## 线程之间的通信方式

- 锁机制：包括互斥锁/量（mutex）、读写锁（reader-writer lock）、自旋锁（spin lock）、条件变量（condition）
  - 互斥锁/量（mutex）：提供了以排他方式防止数据结构被并发修改的方法。
  - 读写锁（reader-writer lock）：允许多个线程同时读共享数据，而对写操作是互斥的。
  - 自旋锁（spin lock）与互斥锁类似，都是为了保护共享资源。互斥锁是当资源被占用，申请者进入睡眠状态；而自旋锁则循环检测保持者是否已经释放锁。
  - 条件变量（condition）：可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。
- 信号量机制(Semaphore)
  - 无名线程信号量
  - 命名线程信号量
- 信号机制(Signal)：类似进程间的信号处理
- 屏障（barrier）：屏障允许每个线程等待，直到所有的合作线程都达到某一点，然后从该点继续执行。

线程间的通信目的主要是用于线程同步，所以线程没有像进程通信中的用于数据交换的通信机制

> 进程之间的通信方式以及优缺点来源于：[进程线程面试题总结](http://blog.csdn.net/wujiafei_njgcxy/article/details/77098977)

### 信号量

信号量是一种特殊的变量，可用于线程同步。它只取自然数值，并且只支持两种操作：

> - P(SV):如果信号量SV大于0，将它减一；如果SV值为0，则挂起该线程。
> - V(SV)：如果有其他进程因为等待SV而挂起，则唤醒，然后将SV+1；否则直接将SV+1。

- 系统调用
  - sem_wait（sem_t *sem）：以原子操作的方式将信号量减1，如果信号量值为0，则sem_wait将被阻塞，直到这个信号量具有非0值。
  - sem_post（sem_t *sem)：以原子操作将信号量值+1。当信号量大于0时，其他正在调用sem_wait等待信号量的线程将被唤醒。

### 互斥量

互斥量又称互斥锁，主要用于线程互斥，不能保证按序访问，可以和条件锁一起实现同步。当进入临界区      时，需要获得互斥锁并且加锁；当离开临界区时，需要对互斥锁解锁，以唤醒其他等待该互斥锁的线程。

- 系统调用
  - pthread_mutex_init:初始化互斥锁
  - pthread_mutex_destroy：销毁互斥锁
  - pthread_mutex_lock：以原子操作的方式给一个互斥锁加锁，如果目标互斥锁已经被上锁，pthread_mutex_lock调用将阻塞，直到该互斥锁的占有者将其解锁。
  - pthread_mutex_unlock:以一个原子操作的方式给一个互斥锁解锁。

### 条件变量

条件变量，用于在线程之间同步共享数据的值。条件变量提供一种线程间通信机制：当某个共享数据达到某个值时，唤醒等待这个共享数据的一个/多个线程。即，当某个共享变量等于某个值时，调用 signal/broadcast。此时操作共享变量时需要加锁。

- 系统调用
  - pthread_cond_init:初始化条件变量
  - pthread_cond_destroy：销毁条件变量
  - pthread_cond_signal：唤醒一个等待目标条件变量的线程。哪个线程被唤醒取决于调度策略和优先级。
  - pthread_cond_wait：等待目标条件变量。需要一个加锁的互斥锁确保操作的原子性。该函数中在进入wait状态前首先进行解锁，然后接收到信号后会再加锁，保证该线程对共享资源正确访问。 



### 进程之间私有和共享的资源

- 私有：地址空间、堆、全局变量、栈、寄存器（0-3G的用户空间）
- 共享：代码段，公共数据，进程目录，进程 ID（3-4G的内核空间）



### 线程之间私有和共享的资源

- 私有：**线程栈，寄存器，程序寄存器**，线程ID，错误返回码，信号屏蔽字，调度优先级
- 共享：文件描述符表，堆，地址空间，全局变量，静态变量，进程代码段，进程的当前目录和进程用户ID与进程组ID



### 多进程与多线程间的对比、优劣与选择

##### 对比

| 对比维度       | 多进程                                                       | 多线程                                                       | 总结     |
| :------------- | :----------------------------------------------------------- | :----------------------------------------------------------- | :------- |
| 数据共享、同步 | 数据共享复杂，需要用 IPC；数据是分开的，同步简单             | 因为共享进程数据，数据共享简单，但也是因为这个原因导致同步复杂 | 各有优势 |
| 内存、CPU      | 占用内存多，切换复杂，CPU 利用率低                           | 占用内存少，切换简单，CPU 利用率高                           | 线程占优 |
| 创建销毁、切换 | 创建销毁、切换复杂，速度慢                                   | 创建销毁、切换简单，速度很快                                 | 线程占优 |
| 编程、调试     | 编程简单，调试简单                                           | 编程复杂，调试复杂                                           | 进程占优 |
| 可靠性         | 进程间不会互相影响                                           | 一个线程挂掉将导致整个进程挂掉                               | 进程占优 |
| 分布式         | 适应于多核、多机分布式；如果一台机器不够，扩展到多台机器比较简单 | 适应于多核分布式                                             | 进程占优 |



##### 优劣

| 优劣 | 多进程                                   | 多线程                                   |
| :--- | :--------------------------------------- | :--------------------------------------- |
| 优点 | 编程、调试简单，可靠性较高               | 创建、销毁、切换速度快，内存、资源占用小 |
| 缺点 | 创建、销毁、切换速度慢，内存、资源占用大 | 编程、调试复杂，可靠性较差               |



##### 选择

- 需要频繁创建销毁的优先用线程
- 需要进行大量计算的优先使用线程
- 强相关的处理用线程，弱相关的处理用进程
- 可能要扩展到多机分布的用进程，多核分布的用线程
- 都满足需求的情况下，用你最熟悉、最拿手的方式

## [协程](https://blog.csdn.net/pinganting/article/details/53750142)

[协程学习笔记](https://blog.csdn.net/somezz/article/details/81265198)

### 协程概述

- 协程是轻量级线程，拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈。
- 协程能保留上一次调用时的状态，即所有局部状态的一个特定组合，每次过程重入时，就相当于进入上一次调用的状态。

### 协程和线程的区别

- 协程最大的优势就是协程极高的执行效率。因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。
- 不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。 

### 应用场景

- I/O 密集型任务。

> - 这一点与多线程有些类似，但协程调用是在一个线程内进行的，是单线程，切换的开销小，因此效率上略高于多线程。
> - 当程序在执行 I/O 时操作时，CPU 是空闲的，此时可以充分利用 CPU 的时间片来处理其他任务。在单线程中，一个函数调用，一般是从函数的第一行代码开始执行，结束于 return 语句、异常或者函数执行（也可以认为是隐式地返回了 None ）。 
> - 有了协程，我们在函数的执行过程中，如果遇到了耗时的 I/O 操作，函数可以临时让出控制权，让 CPU 执行其他函数，等 I/O 操作执行完毕以后再收回控制权。



## Linux 内核的同步方式

### 原因

在现代操作系统里，同一时间可能有多个内核执行流在执行，因此内核其实像多进程多线程编程一样也需要一些同步机制来同步各执行单元对共享数据的访问。尤其是在多处理器系统上，更需要一些同步机制来同步不同处理器上的执行单元对共享的数据的访问。

### 同步方式

- 原子操作
- 信号量（semaphore）
- 读写信号量（rw_semaphore）
- 自旋锁（spinlock）
- 大内核锁（BKL，Big Kernel Lock）
- 读写锁（rwlock）
- 大读者锁（brlock-Big Reader Lock）
- 读-拷贝修改(RCU，Read-Copy Update)
- 顺序锁（seqlock）

> 来自：[Linux 内核的同步机制，第 1 部分](https://www.ibm.com/developerworks/cn/linux/l-synch/part1/)、[Linux 内核的同步机制，第 2 部分](https://www.ibm.com/developerworks/cn/linux/l-synch/part2/)

## LINUX系统中的锁

互斥锁，读写锁，自旋锁

> - 互斥锁：mutex，用于保证在任何时刻，都只能有一个线程访问该对象。**当获取锁操作失败时，线程会进入睡眠**，等待锁释放时被唤醒

> - 读写锁：rwlock，分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作。但是同一时刻只能有一个线程可以获得写锁。其它**获取写锁失败的线程都会进入睡眠状态**，直到写锁释放时被唤醒。 注意：写锁会阻塞其它读写锁。当有一个线程获得写锁在写时，读锁也不能被其它线程获取；写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）。适用于读取数据的频率远远大于写数据的频率的场合。

> - 自旋锁：spinlock，在任何时刻同样只能有一个线程访问对象。但是**当获取锁操作失败时，不会进入睡眠，而是会在原地自旋**，循环检测锁的保持者是否释放，直到锁被释放。这样节省了线程从睡眠状态到被唤醒期间的消耗，在加锁时间短暂的环境下会极大的提高效率。但如果加锁时间过长，则会非常浪费CPU资源。 



## [信号处理机制](http://www.360doc.com/content/16/0804/10/30953065_580685165.shtml)

## [哪两个信号不能忽略](https://www.cnblogs.com/Lynn-Zhang/p/5677118.html)

SIGKILL和SIGSTOP，这两种信号不能被忽略

- 它们向超级用户提供一种使进程终止或停止的可靠方法。
- 如果忽略某些由硬件异常产生的信号（例如非法存储访问或除以0），则进程的行为是示定义的。

## [原子操作和锁机制](https://blog.csdn.net/CringKong/article/details/79966161)

[原子操作实现同步](